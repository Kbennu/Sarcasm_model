# **README: Проект: "Sarcasm Detection"**

## **Описание проекта**
Проект предназначен для классификации текстовых заголовков на два класса:
1. **Sarcasm (сарказм):** Заголовки с саркастическим подтекстом.
2. **Not Sarcasm (не сарказм):** Заголовки без саркастического оттенка.

Модель основана на архитектуре **DistilBERT** и дополнена текстовыми признаками. 
Проект включает обучение модели, её оценку, визуализацию результатов и создание сервиса для работы с моделью.

---

## **1. Подготовка окружения**
- Установлены необходимые библиотеки: pandas, numpy, matplotlib, seaborn, scikit-learn, keras, transformers.
- Загружен датасет (Sarcasm_Headlines_Dataset_v2.json).
- Выполнена проверка данных:
  - Пропуски: отсутствуют.
  - Дубликаты: удалены.

---

## **2. Исследование данных (EDA)**
### **Анализ структуры данных**
- Целевая переменная (is_sarcastic) сбалансирована:
  - 47.5% саркастических заголовков.
  - 52.5% несаркастических заголовков.

### **Анализ текстовых признаков**
- **Длина заголовков:** Средняя длина составляет 60 символов.
  - Саркастические заголовки короче, чем несаркастические.
- **Количество слов:** В среднем 10 слов на заголовок.
  - Несаркастические заголовки содержат больше слов.
- **Пунктуация:**
  - Восклицательные знаки чаще встречаются в несаркастических заголовках.
  - Вопросительные знаки используются редко, но немного чаще в несаркастических заголовках.

### **Корреляция признаков**
- Длина заголовков и количество слов имеют высокую корреляцию (0.91).
- Независимые признаки: средняя длина слов, количество восклицательных и вопросительных знаков.

### **Частотный анализ**
- Часто встречающиеся слова:
  - Саркастические заголовки: используют слова с ироничным подтекстом.
  - Несаркастические заголовки: содержат нейтральные и информативные термины.

---

## **3. Подготовка данных**
- Текст очищен от пунктуации, символов и приведён к нижнему регистру.
- Созданы новые признаки.
- Данные разделены на тренировочную и тестовую выборки (80/20).
- Проведена текстовая векторизация:
   - **TF-IDF:** используется для числового представления текста.
   - **Word embeddings (GloVe):** применяются для улучшения семантического анализа.

---

## **4. Обучение моделей**
Обучены 4 модели с разной сложностью:

1. **Логистическая регрессия (Baseline):**
   - Простая модель, использующая TF-IDF.
   - **Точность:** 82%.

2. **Support Vector Machine (SVM):**
   - Использует TF-IDF и оптимизированные гиперпараметры.
   - **Точность:** 85%.

3. **LSTM:**
   - Использует GloVe эмбеддинги и текстовые последовательности.
   - **Точность:** 88%.

4. **DistilBERT:**
   - Модель трансформеров для семантического анализа.
   - **Точность:** 92%.

---

## **5. Оценка моделей**
### **Метрики качества**
- **Accuracy (точность):** Точность классификации.
- **Precision, Recall, F1-score:** Для оценки качества предсказаний.
- **Скорость инференса:** Время, необходимое для обработки тестовой выборки.

#### **Сравнение моделей**

| Модель                  | Точность (%) | Precision | Recall | F1-score | Скорость инференса (с) |
|-------------------------|--------------|-----------|--------|----------|-------------------------|
| Logistic Regression     | 82           | 0.81      | 0.82   | 0.81     | 0.02                    |
| SVM                     | 85           | 0.84      | 0.85   | 0.84     | 0.08                    |
| LSTM                    | 88           | 0.87      | 0.88   | 0.87     | 0.45                    |
| DistilBERT              | 92           | 0.91      | 0.92   | 0.91     | 1.20                    |

---

## **6. Выбор модели**
- **Наилучшая модель:** DistilBERT.
  - **Причины выбора:**
    - Высокая точность (92%).
    - Учитывает семантические и контекстные связи в тексте.
  - **Рекомендации:**
    - Использовать DistilBERT для финальной классификации.
    - Рассмотреть ансамблевые подходы для повышения точности.


## **7. Структура проекта**

### Основные папки:
1. **sarcasm_app/** — файлы для работы сервиса.
   - script.py — запуск приложения с использованием Streamlit.
   - requirements.txt — зависимости проекта.
   - HybridModel_state_dict.pth — обученная модель (https://drive.google.com/drive/folders/101oMtemKn3OY14wUXw4j0-sDWFvy5yCG?usp=drive_link).
   - HybridTokenizer — токенизатор для обработки текста.
   - README.md
2. **sarcasm_model/** — файлы для разработки и обучения модели.
   - sarcasm_model.py — ноутбук с экспериментами.
   - sarcasm_model.pdf — ноутбук с экспериментами.
   - **moduls/** — вспомогательные модули:
     - data_processing.py — предобработка данных.
     - feature_engineering.py — выделение признаков.
     - hybrid_model.py — архитектура модели.
     - train.py — обучение модели.
     - save_load.py — сохранение/загрузка модели.
   - **pic/** — графики и визуализации.
   - README.txt

---

## **8. Как обучить модель:**

### Предобработка данных
Используйте модуль data_processing.py для очистки и подготовки данных.

### Выделение признаков
Модуль feature_engineering.py выделяет текстовые и числовые признаки.

### Обучение модели
Запустите скрипт train.py для обучения:
***bash
python sarcasm_model/moduls/train.py

### 4. Сохранение модели
Используйте модуль save_load.py для сохранения модели:
***python
from moduls.save_load import save_model
save_model(model, "HybridModel_state_dict.pth")

---

## **9. Инструменты проекта**

### Основные библиотеки:
- **Transformers** (DistilBERT): обработка текста и работа с моделью.
- **scikit-learn:** машинное обучение, логистическая регрессия, SVM.
- **Keras:** реализация LSTM.
- **Streamlit:** создание интерфейса для работы с моделью.
- **Podman:** контейнеризация приложения.

---

## **10. Инструкция по запуску проекта**

1. **Установите зависимости:**
   Убедитесь, что у вас установлен Python 3.10 или выше.
   ***bash
   pip install -r sarcasm_app/requirements.txt

2. **Обучите модель:**
   Запустите train.py для обучения модели.

3. **Тестирование:**
   Используйте sarcasm_model.py для тестирования предсказаний.

4. **Развёртывание:**
   Для создания сервиса следуйте инструкциям в отдельном README(./sarcasm_app/README.md).

---

## **11. Визуализация:**
Скриншоты работы сервиса.

---

## **12. Заключение**
Проект представляет собой завершённое решение для классификации текстовых заголовков на основе сарказма. Он включает этапы предобработки данных, обучения модели и создания сервиса для использования. Репозиторий организован таким образом, чтобы облегчить доработку и масштабирование проекта.
